<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Ba≈üak Melis √ñcal</title>
  
  <meta name="author" content="Melis √ñcal">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p style="text-align:center">
                  <name>Melis √ñcal</name>
                </p>
                <p> I am a third-year PhD student in the field of computer vision and machine learning, supervised by <a href="https://staff.fnwi.uva.nl/th.gevers/">Prof. Theo Gevers</a> and co-supervised by <a href="https://karaoglusezer.github.io/">Dr. Sezer Karaoƒülu</a> at the <a href="https://ivi.fnwi.uva.nl/uvaboschdeltalab/">Delta Lab</a>, which is a collaboration between <a href="https://www.uva.nl/en">the University of Amsterdam</a> and <a href="https://www.bosch-ai.com/">Bosch</a>. I closely collaborate with <a href="https://www.linkedin.com/in/tatarchm/?originalSubdomain=de">Dr. Maxim Tatarchenko</a> and <a href="https://www.linkedin.com/in/vien-ngo-383ba3a6/">Dr. Vien Ngo</a>. My research interests mainly lie in <b>scene understanding</b>, <b>3D reconstruction</b>, <b>view synthesis</b> and <b>unsupervised learning</b> for <b>autonomous driving</b> and <b>robotic</b> applications.
                </p>
                <p>
                  In 2022, I obtained my Master‚Äôs degree in Informatics from <a href="https://www.tum.de/en/">Technical University of Munich</a> with a focus on computer vision and machine learning. I worked on several research projects at the <a href="https://vision.in.tum.de/">Computer Vision Group</a> led by <a href="https://vision.in.tum.de/members/cremers">Prof. Daniel Cremers</a>. I completed my master's thesis on 3D reconstruction at the <a href="https://mlr.in.tum.de//">Smart Robotics Lab</a> under <a href="https://mlr.in.tum.de/members/leuteneg">Prof. Stefan Leutenegger</a>.
                </p>
                <p style="text-align:center">
                  <a href="mailto:melisbasakocal@gmail.com">Email</a> &nbsp/&nbsp
                  <a href="https://www.linkedin.com/in/basak-melis-ocal/">LinkedIn</a> &nbsp/&nbsp
                  <a href="https://scholar.google.com/citations?user=hn8NZSsAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                  <a href="https://github.com/basakmelisocal/">Github</a> &nbsp/&nbsp
                  <a href="https://twitter.com/basakmelisocal">Twitter</a>
                </p>
              </td>
              <td style="padding:2.5%;width:44%;max-width:44%">
                <a href="images/MelisOcal.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/MelisOcal.png" class="hoverZoomLink"></a>  
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>News</heading>
                <p>
                	<b>July, 2024:</b> Our work <a href="https://arxiv.org/abs/2407.20727">SceneTeller: Language-to-3D Scene Generation</a> was accepted at <a href="https://eccv2024.ecva.net/">ECCV 2024</a>! The <a href="https://github.com/sceneteller/SceneTeller">code</a> is now available!
                </p>
                <p>
                	<b>April, 2024:</b> I gave a talk on <a href="https://link.springer.com/article/10.1007/s10489-023-04478-8">Learning Vision Based Autonomous Lateral Vehicle Control without Supervision</a> with <a href="https://idilsulo.github.io/">ƒ∞dil S√ºlo</a> to ATS Research group at Scania.
                </p>
                <p>
                	<b>January, 2023:</b> Our work <a href="https://link.springer.com/article/10.1007/s10489-023-04478-8">Learning Vision Based Autonomous Lateral Vehicle Control without Supervision</a> was accepted at Applied Intelligence!
                </p>	
                <p>
                  <b>September, 2022:</b> I started my PhD in computer vision, under the supervision of <a href="https://staff.fnwi.uva.nl/th.gevers/">Prof. Theo Gevers</a> at the <a href="https://ivi.fnwi.uva.nl/uvaboschdeltalab/">UvA-Bosch Delta Lab</a>!
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Research</heading>
              </td>
            </tr>
          </tbody></table>      
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr onmouseout="realdiff_stop()" onmouseover="realdiff_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='realdiff_image'><video class="video-realdiff" width=100% muted autoplay loop>
                  <source src="images2/realdiff.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images2/realdiff.jpg' width=100%>
                </div>
                <script type="text/javascript">
                  function realdiff_start() {
                    document.getElementById('realdiff_image').style.opacity = "1";
                    var videos = document.querySelectorAll(".video-realdiff");
                    videos.forEach(function(video) {
                    video.playbackRate = 1.0;
                    });
                  }

                  function realdiff_stop() {
                    document.getElementById('realdiff_image').style.opacity = "0";
                  }
                  realdiff_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://realdiff.github.io/">
                  <span class="papertitle">RealDiff: Real-world 3D Shape Completion using Self-Supervised Diffusion Models</span>
                </a>
                <br>
                <strong>Melis √ñcal</strong>,
                <a href="https://www.linkedin.com/in/tatarchm/?originalSubdomain=de">Maxim Tatarchenko</a>,
                <a href="https://karaoglusezer.github.io/">Sezer Karaoƒülu</a>,
                <a href="https://staff.fnwi.uva.nl/th.gevers/">Theo Gevers</a>
                <br>
                <em>Preprint (arXiv)</em>, 2024
                <br>
                <a href="https://realdiff.github.io/">project page</a>
                /
                <a href="https://arxiv.org/abs/2409.10180">arXiv</a>
                <p></p>
                <p>
                   RealDiff formulates point cloud completion as a conditional generation problem directly on real-world measurements in a self-supervised way. To better deal with noisy observations, we leverage additional geometric cues.
                </p>
              </td>
            </tr>

            <tr onmouseout="sceneteller_stop()" onmouseover="sceneteller_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='sceneteller_image'><video class="video-small" width=100% muted autoplay loop>
                  <source src="images2/sceneteller.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images2/sceneteller.jpg' width=100%>
                </div>
                <script type="text/javascript">
                  function sceneteller_start() {
                    document.getElementById('sceneteller_image').style.opacity = "1";
                    var videos = document.querySelectorAll(".video-small");
                    videos.forEach(function(video) {
                    video.playbackRate = 10.0;
                    });
                  }

                  function sceneteller_stop() {
                    document.getElementById('sceneteller_image').style.opacity = "0";
                  }
                  sceneteller_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://sceneteller.github.io/">
                  <span class="papertitle">SceneTeller: Language-to-3D Scene Generation</span>
                </a>
                <br>
                <strong>Melis √ñcal</strong>,
                <a href="https://www.linkedin.com/in/tatarchm/?originalSubdomain=de">Maxim Tatarchenko</a>,
                <a href="https://karaoglusezer.github.io/">Sezer Karaoƒülu</a>,
                <a href="https://staff.fnwi.uva.nl/th.gevers/">Theo Gevers</a>
                <br>
                <em>European Conference on Computer Vision</em>, 2024
                <br>
                <a href="https://sceneteller.github.io/">project page</a>
                /
                <a href="https://arxiv.org/abs/2407.20727">arXiv</a>
                <p></p>
                <p>
                  Built using in-context learning, CAD model retrieval and 3DGS-based stylization, SceneTeller generates realistic and high-quality 3D spaces from natural language prompts.
                </p>
              </td>
            </tr>

            <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='smerf_image'><video  width=100% muted autoplay loop>
                  <source src="images2/nndriving.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images2/nndriving.png' width=100%>
                </div>
                <script type="text/javascript">
                  function smerf_start() {
                    document.getElementById('smerf_image').style.opacity = "1";
                  }

                  function smerf_stop() {
                    document.getElementById('smerf_image').style.opacity = "0";
                  }
                  smerf_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://github.com/idilsulo/nn-driving">
                  <span class="papertitle">Learning Vision Based Autonomous Lateral Vehicle Control without Supervision</span>
                </a>
                <br>
                <a href="">Qadeer Khan</a>,
                <a href="https://idilsulo.github.io/">ƒ∞dil S√ºlo</a>,
                <strong>Melis √ñcal</strong>,
                <a href="https://cvg.cit.tum.de/members/cremers">Daniel Cremers</a>
                <br>
                <em>Applied Intelligence</em>, 2023
                <br>
                <a href="https://github.com/idilsulo/nn-driving">project page</a>
                /
                <a href="https://link.springer.com/article/10.1007/s10489-023-04478-8">paper</a>
                <p></p>
                <p>
                  A lateral vehicle control network can be trained from only an unlabeled sequence of images using novel view synthesis, without the need for a specialized setup on the car. 
                </p>
              </td>
            </tr>

            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images2/thesis.png" alt="blind-date" width=100%>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://drive.google.com/file/d/1NGVTXO0b0POhQ90Jfw4SHXJiF4DbPhzH/view?usp=sharing">
                  <span class="papertitle">Master's Thesis - Deep Learning Based 3D Reconstruction Using Images With Known Poses</span>
                </a>
                <br>
                <strong>Melis √ñcal</strong>
                <br>
                <em>Technical University of Munich</em>, 2022
                <br>
                <p></p>
              </td>
            </tr>

            
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Reviewing</heading>
                <p>
                	CVPR, ICCV/ECCV, ICLR, NeurIPS 
                </p>
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <heading>Teaching</heading>
                <p>
                	Computer Vision 1, 2023-2024 <br>
                	Computer Vision 2, 2023-2024
                </p>

              </td>
            </tr>
          </tbody></table>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <p style="text-align:right;font-size:small;">
                   This website is based on Jon Barron's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>.
                  </p>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>

</html>
